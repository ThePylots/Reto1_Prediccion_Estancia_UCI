{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a9d267-4bb9-424b-90dd-81d4e7f3d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as db\n",
    "import pandas as pd\n",
    "#import featuretools as ft\n",
    "import json\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4bb256-f546-49be-b61e-394658a85d6f",
   "metadata": {},
   "source": [
    "<center><h2><b>Leer DB</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9336aab-0f10-46c0-b174-1b30352524b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_14976\\2990043772.py:21: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs[ds_name] = pd.read_csv('../db/csv/' + ds_name + '.csv')\n"
     ]
    }
   ],
   "source": [
    "# Hacer una query SQL\n",
    "def sql_query(q):\n",
    "    conn = db.connect('../db/sqlite/eicu_v2_0_1.sqlite3')\n",
    "    df = pd.read_sql_query(q, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Leer todos los CSV\n",
    "def read_csvs():\n",
    "    #import os\n",
    "    #print( os.getcwd())\n",
    "    datasets = [ 'admissiondrug', 'admissionDx', 'allergy', 'apacheApsVar', 'apachePatientResult', 'apachePredVar', 'carePlanCareProvider', 'carePlanEOL', 'carePlanGeneral',\n",
    "                 'carePlanGoal', 'carePlanInfectiousDisease', 'customLab', 'diagnosis', 'hospital', 'infusiondrug', 'intakeOutput', 'lab', 'medication', 'microLab', 'note',\n",
    "                 'nurseAssessment', 'nurseCare', 'nurseCharting', 'pastHistory', 'patient', 'physicalExam', 'respiratoryCare', 'respiratoryCharting', 'treatment', 'vitalAperiodic',\n",
    "                 'vitalPeriodic']\n",
    "\n",
    "    dfs = {}\n",
    "\n",
    "    for ds_name in datasets:\n",
    "        dfs[ds_name] = pd.read_csv('../db/csv/' + ds_name + '.csv')\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "dfs = read_csvs()\n",
    "has_dropped_keys = False # Para que no se droppeen cada vez que se ejecuta la celda siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c77a8cf-b3e3-4d47-b5df-5b63d47037a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropear IDs de todas las tablas (primera columna)\n",
    "def drop_keys(dfs):\n",
    "    for df_key in dfs.keys():\n",
    "        if df_key not in ('hospital', 'patient'): # No dropear hospitalId o patientUnitStayId\n",
    "            df = dfs[df_key]\n",
    "            dfs[df_key] = df.drop(columns=[df.columns.values[0]])\n",
    "\n",
    "if not has_dropped_keys:\n",
    "    drop_keys(dfs)\n",
    "    has_dropped_keys = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684e93d4-866d-4239-913f-9cb516e092e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Eliminar filas duplicadas\n",
    "for df_name in dfs:\n",
    "    dfs[df_name] = dfs[df_name].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4586adc8-451b-4e70-9bc0-c30e6fa0ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ajustar todos los offsets al múltiplo más cercano de 100 mins para reducir el número de filas duplicadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f6a589-8767-45a1-aa96-8c27f9208fce",
   "metadata": {},
   "source": [
    "<center><h2><b>admissionDx</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997cf1e9-48d7-4423-9bee-f12eef9822d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Son los medicamentos más usados en las admisiones\n",
    "def has_commun_drug_A(row):\n",
    "    #return 1 if row['drugname'].strip() == \"ASPIRIN\" else 0\n",
    "    drug = row ['drugname'].strip()\n",
    "       \n",
    "    if drug == \"ASPIRIN\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def has_commun_drug_L(row):\n",
    "    drug = row ['drugname'].strip()\n",
    "    \n",
    "    if drug == 'LISINOPRIL':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def has_commun_drug_Li(row):\n",
    "    drug = row ['drugname'].strip()\n",
    "    \n",
    "    if drug in 'LASIX':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d281dfac-28e9-462d-a33d-d7a2de469475",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['admissiondrug'] = dfs['admissiondrug'].drop(columns=[\n",
    "    'drugoffset', 'drugenteredoffset', 'drugnotetype', 'specialtytype', 'rxincluded', 'writtenineicu', 'drugunit', 'drugdosage',\n",
    "    'drugadmitfrequency', 'drughiclseqno', 'usertype'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20a7d15f-5d19-4a29-b47a-8d66c00c7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dfs = dfs[\"admissiondrug\"][\"patientunitstayid\"]\n",
    "\n",
    "# Creamos nuevas columnas\n",
    "commun_drug_A   = dfs[\"admissiondrug\"].apply(lambda row : has_commun_drug_A(row), axis=1)\n",
    "commun_drug_L   = dfs[\"admissiondrug\"].apply(lambda row : has_commun_drug_L(row), axis=1)\n",
    "commun_drug_Li  = dfs[\"admissiondrug\"].apply(lambda row : has_commun_drug_Li(row), axis=1)\n",
    "\n",
    "\n",
    "_commun_drug_A  = pd.DataFrame(commun_drug_A, columns=['ASPIRIN'])\n",
    "_commun_drug_L  = pd.DataFrame(commun_drug_L, columns=['LISINOPRIL'])\n",
    "_commun_drug_Li = pd.DataFrame(commun_drug_Li, columns=['LASIX'])\n",
    "\n",
    "\n",
    "dfs[\"admissiondrug\"] = pd.concat([_dfs, _commun_drug_A,_commun_drug_L,_commun_drug_Li], axis=1)\n",
    "\n",
    "#Eliminamos columnas duplicadas\n",
    "dfs['admissiondrug'] = dfs['admissiondrug'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "756e6b0e-ff54-4d1b-9749-aa117942a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"admissiondrug\"] = dfs[\"admissiondrug\"].groupby(['patientunitstayid']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5ecd2dc-9750-4995-8d53-3bf0839b3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_boolean (data, column):\n",
    "    data = dfs[\"admissiondrug\"].copy()                 \n",
    "    data[column] = data[column].astype(bool)          \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5408b193-91fa-45b0-9664-8e05c6e2d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"admissiondrug\"] = int_to_boolean (dfs[\"admissiondrug\"], 'ASPIRIN')\n",
    "dfs[\"admissiondrug\"] = int_to_boolean (dfs[\"admissiondrug\"], 'LISINOPRIL')\n",
    "dfs[\"admissiondrug\"] = int_to_boolean (dfs[\"admissiondrug\"], 'LASIX')\n",
    "dfs[\"admissiondrug\"] = dfs[\"admissiondrug\"].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059c4b7b-6a89-415d-8140-acf95cb3bb9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>admissionDx</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5556897-5281-4e85-b754-b7d44f494efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "#dfs['admissionDx'] = dfs['admissionDx'].drop(columns=[\n",
    "#    'admitdxtext', # En la gran mayoría de los casos es igual a admitdxname\n",
    "#], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5588a098-90d0-46fe-9742-64c225a56729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Nota: Es una mierda porque tiene mucho más sentido con onehot, pero hay un huevo de diagnósticos y como 10~20 notas adicionales\n",
    "# TODO: diag1 = 4 ??\n",
    "#\n",
    "\n",
    "# admitdxpath - admitdxname: Cada patientunistayid tiene n filas relacionadas con todos las diagnosis encontradas.\n",
    "def parse_admitdx(group):\n",
    "    pusID, group_df = group\n",
    "    diagnosis = []\n",
    "    additionalinfo = []\n",
    "    \n",
    "    for i, row in group_df.iterrows():\n",
    "        if row['admitdxname'] in ('No', 'Yes'):\n",
    "            path_parts = row['admitdxpath'].split('|')\n",
    "            mode = path_parts[-2]\n",
    "            \n",
    "            additionalinfo.append(mode + ' ' + row['admitdxname'])\n",
    "        else:\n",
    "            diagnosis.append(row['admitdxname'])\n",
    "            \n",
    "    # Rellenar 3 huecos en diagnosis y 2 en additionalinfo\n",
    "    diagnosis = (sorted(diagnosis) + ['No' for _ in range(3)])[:3]\n",
    "    additionalinfo = (sorted(additionalinfo) + ['No' for _ in range(3)])[:3]\n",
    "    \n",
    "    return [pusID] + diagnosis + additionalinfo\n",
    "\n",
    "new_df = pd.DataFrame(columns=['patientunitstayid', 'diag1', 'diag2', 'diag3', 'additional1', 'additional2', 'additional3'])\n",
    "for i,  group in enumerate(dfs['admissionDx'].groupby('patientunitstayid')):\n",
    "    row = parse_admitdx(group)\n",
    "    new_df.loc[i] = row\n",
    "\n",
    "#new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c0aa7ec-ef11-4715-9f8b-89016060d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_admitdxname(row):\n",
    "    admitdxname = row ['admitdxname']\n",
    "    \n",
    "    m = re.search('^(\\w+)', admitdxname)\n",
    "    \n",
    "    return m.group(0)\n",
    "\n",
    "# Drop columns\n",
    "dfs['admissionDx'] = dfs['admissionDx'].drop(columns=[\n",
    "    'admitdxtext', # En la gran mayoría de los casos es igual a admitdxname\n",
    "], axis=1)\n",
    "\n",
    "dfs['admissionDx']['admitdxname'] = dfs['admissionDx'].apply(lambda row : clean_admitdxname(row), axis=1)\n",
    "\n",
    "# Filtramos y quitamos los Yes y No, no tienen mucho sentido\n",
    "df = dfs['admissionDx']\n",
    "dfs['admissionDx'] = df[df['admitdxname'] != 'Yes']\n",
    "df = dfs['admissionDx']\n",
    "dfs['admissionDx'] = df[df['admitdxname'] != 'No']\n",
    "\n",
    "#Cardiovascular      983\n",
    "#Respiratory         363\n",
    "#Neurologic          318\n",
    "\n",
    "def has_common_admission_C(row):\n",
    "    drug = row ['admitdxname'].strip()\n",
    "       \n",
    "    if drug == \"Cardiovascular\": \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def has_common_admission_R(row):\n",
    "    drug = row ['admitdxname'].strip()\n",
    "    \n",
    "    if drug == 'Respiratory':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def has_common_admission_N(row):\n",
    "    drug = row ['admitdxname'].strip()\n",
    "    \n",
    "    if drug in 'Neurologic':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "_dfs = dfs[\"admissionDx\"][\"patientunitstayid\"]\n",
    "\n",
    "# Creamos nuevas columnas\n",
    "common_admission_C   = dfs[\"admissionDx\"].apply(lambda row : has_common_admission_C(row), axis=1)\n",
    "common_admission_R   = dfs[\"admissionDx\"].apply(lambda row : has_common_admission_R(row), axis=1)\n",
    "common_admission_N   = dfs[\"admissionDx\"].apply(lambda row : has_common_admission_N(row), axis=1)\n",
    "\n",
    "\n",
    "_common_admission_C  = pd.DataFrame(common_admission_C, columns=['Cardiovascular'])\n",
    "_common_admission_R  = pd.DataFrame(common_admission_R, columns=['Respiratory'])\n",
    "_common_admission_N  = pd.DataFrame(common_admission_N, columns=['Neurologic'])\n",
    "\n",
    "\n",
    "dfs[\"admissionDx\"] = pd.concat([_dfs, _common_admission_C,_common_admission_R,_common_admission_N], axis=1)\n",
    "\n",
    "dfs[\"admissionDx\"] = dfs[\"admissionDx\"].groupby(['patientunitstayid']).max()\n",
    "\n",
    "dfs[\"admissionDx\"] = dfs[\"admissionDx\"].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e2262e-50cd-4a25-af2d-b370e5e86fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>allergy</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfd43fe2-ced7-4561-b428-d78439e998aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>allergyoffset</th>\n",
       "      <th>drugname</th>\n",
       "      <th>allergytype</th>\n",
       "      <th>allergyname</th>\n",
       "      <th>drughiclseqno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243097</td>\n",
       "      <td>2549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non Drug</td>\n",
       "      <td>penicillins</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243097</td>\n",
       "      <td>1288</td>\n",
       "      <td>CODEINE PHOSPHATE</td>\n",
       "      <td>Drug</td>\n",
       "      <td>CODEINE PHOSPHATE</td>\n",
       "      <td>1721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>243097</td>\n",
       "      <td>2549</td>\n",
       "      <td>CODEINE PHOSPHATE</td>\n",
       "      <td>Drug</td>\n",
       "      <td>CODEINE PHOSPHATE</td>\n",
       "      <td>1721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243097</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non Drug</td>\n",
       "      <td>penicillins</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243097</td>\n",
       "      <td>3988</td>\n",
       "      <td>CODEINE PHOSPHATE</td>\n",
       "      <td>Drug</td>\n",
       "      <td>CODEINE PHOSPHATE</td>\n",
       "      <td>1721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>3351763</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non Drug</td>\n",
       "      <td>latex</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>3351763</td>\n",
       "      <td>14</td>\n",
       "      <td>LEVAQUIN</td>\n",
       "      <td>Drug</td>\n",
       "      <td>LEVAQUIN</td>\n",
       "      <td>12383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>3353113</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non Drug</td>\n",
       "      <td>Contrast Dye</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>3353113</td>\n",
       "      <td>77</td>\n",
       "      <td>PENICILLIN G BENZATHINE</td>\n",
       "      <td>Drug</td>\n",
       "      <td>PENICILLIN G BENZATHINE</td>\n",
       "      <td>3941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>3353113</td>\n",
       "      <td>77</td>\n",
       "      <td>LISINOPRIL</td>\n",
       "      <td>Drug</td>\n",
       "      <td>LISINOPRIL</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patientunitstayid  allergyoffset                 drugname allergytype  \\\n",
       "0                243097           2549                      NaN    Non Drug   \n",
       "1                243097           1288        CODEINE PHOSPHATE        Drug   \n",
       "2                243097           2549        CODEINE PHOSPHATE        Drug   \n",
       "3                243097             21                      NaN    Non Drug   \n",
       "4                243097           3988        CODEINE PHOSPHATE        Drug   \n",
       "...                 ...            ...                      ...         ...   \n",
       "2470            3351763             14                      NaN    Non Drug   \n",
       "2471            3351763             14                 LEVAQUIN        Drug   \n",
       "2472            3353113             77                      NaN    Non Drug   \n",
       "2473            3353113             77  PENICILLIN G BENZATHINE        Drug   \n",
       "2474            3353113             77               LISINOPRIL        Drug   \n",
       "\n",
       "                  allergyname  drughiclseqno  \n",
       "0                 penicillins            NaN  \n",
       "1           CODEINE PHOSPHATE         1721.0  \n",
       "2           CODEINE PHOSPHATE         1721.0  \n",
       "3                 penicillins            NaN  \n",
       "4           CODEINE PHOSPHATE         1721.0  \n",
       "...                       ...            ...  \n",
       "2470                    latex            NaN  \n",
       "2471                 LEVAQUIN        12383.0  \n",
       "2472             Contrast Dye            NaN  \n",
       "2473  PENICILLIN G BENZATHINE         3941.0  \n",
       "2474               LISINOPRIL          132.0  \n",
       "\n",
       "[2475 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['allergy'] = dfs['allergy'].drop(columns=[\n",
    "    'allergyenteredoffset', # No sirve de mucho\n",
    "    'allergynotetype', # No es relevante\n",
    "    'usertype', # No importa mucho quien la haya encontrado\n",
    "    'rxincluded', # Probablemente no tenga mucha influencia\n",
    "    'specialtytype', # Probablemente no tenga mucha influencia\n",
    "    'writtenineicu' # TODO: Es posible que esta sea importante\n",
    "])\n",
    "\n",
    "#\n",
    "# Dividir en dos tablas de drogas y no drogas para quitar NaNs y eliminar columnas\n",
    "#\n",
    "dfs['_allergyDrug']    = dfs['allergy'][dfs['allergy']['allergytype'] == 'Drug']\\\n",
    "    .drop(columns=['allergytype', 'allergyname']) # allergyname siempre es igual a drugname\n",
    "dfs['_allergyNonDrug'] = dfs['allergy'][dfs['allergy']['allergytype'] == 'Non Drug']\\\n",
    "    .drop(columns=['allergytype', 'drugname', 'drughiclseqno'])\n",
    "\n",
    "dfs.pop('allergy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c6f87-6c37-4cea-8c3d-2298b57267ba",
   "metadata": {},
   "source": [
    "<center><h2><b>apacheapsvar</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01b2aefc-41e9-4fe1-a39a-00d04707328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID ya dropeada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a0fc4-727f-4bf2-8376-26e7eaf3fdc4",
   "metadata": {},
   "source": [
    "<center><h2><b>apachepatientresult</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0fa0b-4534-4abf-8243-68a8e75e6712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6397fbf-63c2-4ccd-9492-53fda3edf3ea",
   "metadata": {},
   "source": [
    "<center><h2><b>Apachepredvar</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5619ff-ddae-4825-8c82-1f8c9c3cd348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c237f81-698f-4d90-a88b-40e2f8a581fa",
   "metadata": {},
   "source": [
    "<center><h2><b>careplancareprovider</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae87272e-e070-4070-ac34-7ac1bc29a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar NaN y Uknown de interventioncategory reemplazando los valores por los 3 más frecuentes\n",
    "def clean_interventioncategory(categ):\n",
    "    if categ == categ and categ != 'Unknown': # No NaN\n",
    "        return categ\n",
    "    else:\n",
    "        rand = random.randint(0, 2)\n",
    "        categs = ['I', 'II', 'III']\n",
    "        return categs[rand]\n",
    "\n",
    "\n",
    "dfs['carePlanCareProvider'] = dfs['carePlanCareProvider'].drop(columns=[\n",
    "    'providertype', # Todo nulls\n",
    "    'managingphysician', # No consideramos que sean importantes para que el algoritmo aprenda\n",
    "    'activeupondischarge', # No consideramos que sean importantes para que el algoritmo aprenda\n",
    "])\n",
    "\n",
    "# Rellenamos categoria de Intervención\n",
    "dfs['carePlanCareProvider']['interventioncategory']   = dfs['carePlanCareProvider']['interventioncategory'].apply(clean_interventioncategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "274eac34-8a6f-4e6c-935e-d1adbc18d79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_14976\\3194540165.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs['carePlanCareProvider']['careprovidersaveoffset']   =  dfs['carePlanCareProvider'].apply(lambda row : clean_careprovidersaveoffset(row, dfs['carePlanCareProvider']), axis = 1)\n"
     ]
    }
   ],
   "source": [
    "dfs['carePlanCareProvider']['specialty'].value_counts()[:3] # -> internal medicine:1005 /  cardiology:561 / hospitalist:554\n",
    "\n",
    "# Filtramos y nos quedamos con las specialty más comunes\n",
    "df = dfs['carePlanCareProvider']\n",
    "dfs['carePlanCareProvider'] = df[df.specialty.isin (['internal medicine', 'cardiology', 'hospitalist'])]\n",
    "\n",
    "# Sumamos los offsets con mismo patientid y misma especialidad \n",
    "def clean_careprovidersaveoffset(row, df):           \n",
    "    return  df[(df['patientunitstayid']==row['patientunitstayid']) & (df['specialty']==row['specialty'])]['careprovidersaveoffset'].sum()\n",
    "\n",
    "# 2120 rows × 4 columns\n",
    "dfs['carePlanCareProvider']['careprovidersaveoffset']   =  dfs['carePlanCareProvider'].apply(lambda row : clean_careprovidersaveoffset(row, dfs['carePlanCareProvider']), axis = 1)\n",
    "\n",
    "# Quitamos duplicidad -> 1416 rows × 4 columns\n",
    "dfs['carePlanCareProvider'] = dfs['carePlanCareProvider'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a2b66c-e34c-4b98-a7f9-10ba1c6cee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(dfs[\"carePlanCareProvider\"][\"interventioncategory\"]) -> I / II / III / IV\n",
    "# specialty -> internal medicine:1005 /  cardiology:561 / hospitalist:554\n",
    "\n",
    "def has_category_I (row):\n",
    "    return 1 if row[\"interventioncategory\"] == 'I' else 0\n",
    "def has_category_II (row):\n",
    "    return 1 if row[\"interventioncategory\"] == 'II' else 0\n",
    "def has_category_III (row):\n",
    "    return 1 if row[\"interventioncategory\"] == 'III' else 0\n",
    "def has_category_IV (row):\n",
    "    return 1 if row[\"interventioncategory\"] == 'IV' else 0\n",
    "\n",
    "def has_hospitalist (row):\n",
    "    return row['careprovidersaveoffset'] if row['specialty'] == 'hospitalist' else 0\n",
    "\n",
    "def has_cardiology (row):\n",
    "    return row['careprovidersaveoffset'] if row['specialty'] == 'cardiology' else 0\n",
    "\n",
    "def has_internal_medicine (row):\n",
    "    return row['careprovidersaveoffset'] if row['specialty'] == 'internal medicine' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f589d8b5-442e-48a2-98d6-94e23fc75bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dfs = dfs[\"carePlanCareProvider\"][\"patientunitstayid\"]\n",
    "\n",
    "# Creamos nuevas columnas\n",
    "category_I   = dfs[\"carePlanCareProvider\"].apply(lambda row : has_category_I(row), axis=1)\n",
    "category_II  = dfs[\"carePlanCareProvider\"].apply(lambda row : has_category_II(row), axis=1)\n",
    "category_III = dfs[\"carePlanCareProvider\"].apply(lambda row : has_category_III(row), axis=1)\n",
    "category_IV  = dfs[\"carePlanCareProvider\"].apply(lambda row : has_category_IV(row), axis=1)\n",
    "\n",
    "category_hospital           = dfs[\"carePlanCareProvider\"].apply(lambda row : has_hospitalist(row), axis=1)\n",
    "category_cardiology         = dfs[\"carePlanCareProvider\"].apply(lambda row : has_cardiology(row), axis=1)\n",
    "category_internal_medicine  = dfs[\"carePlanCareProvider\"].apply(lambda row : has_internal_medicine(row), axis=1)\n",
    "\n",
    "# Vemos si hay intervenciones y de que tipo son\n",
    "_category_I    = pd.DataFrame(category_I, columns=['Intervencion_I'])\n",
    "_category_II   = pd.DataFrame(category_II, columns=['Intervencion_II'])\n",
    "_category_III  = pd.DataFrame(category_III, columns=['Intervencion_III'])\n",
    "_category_IV   = pd.DataFrame(category_IV, columns=['Intervencion_IV'])\n",
    "\n",
    "# Juntamos intervenciones y agrupamos en base a patientId escogiendo el max (1 or 0)\n",
    "Intervention = pd.concat([_dfs, _category_I,_category_II,_category_III, _category_IV], axis=1)\n",
    "Intervention = Intervention.groupby(['patientunitstayid']).max()\n",
    "\n",
    "# Similar a intervenciones pero con las especialidades más comunes\n",
    "_category_hospital           = pd.DataFrame(category_hospital, columns=['Categoria_Hospital'])\n",
    "_category_cardiology         = pd.DataFrame(category_cardiology, columns=['Categoria_Cardiology'])\n",
    "_category_internal_medicine  = pd.DataFrame(category_internal_medicine, columns=['Categoria_Internal_Medicine'])\n",
    "\n",
    "# Similar pero sumando \n",
    "medicine = pd.concat([_dfs, _category_hospital ,_category_cardiology,_category_internal_medicine ], axis=1)\n",
    "medicine = medicine.drop_duplicates()\n",
    "medicine = medicine.groupby(['patientunitstayid']).sum()\n",
    "\n",
    "dfs['carePlanCareProvider'] = pd.concat([medicine, Intervention], axis=1)\n",
    "dfs['carePlanCareProvider'] = dfs['carePlanCareProvider'].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e5bdc9-0156-4c2c-b7c3-9d513d32f213",
   "metadata": {},
   "source": [
    "<center><h2><b>Careplaneol</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a22538b7-7673-438f-bab3-84e33524f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya está lo suficientemente limpia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828a859-9c3a-4361-b3fe-6ec42c24a150",
   "metadata": {},
   "source": [
    "<center><h2><b>careplangeneral</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f994c40a-67ff-4c9f-975b-6ba0f3917afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay 15 filas con valor nulo en la columna cplitemvalue, asi que eliminamos esas filas\n",
    "dfs['carePlanGeneral'] = dfs['carePlanGeneral'].dropna()\n",
    "\n",
    "dfs['carePlanGeneral'] = dfs['carePlanGeneral'].drop(columns=[\n",
    "    'activeupondischarge', \n",
    "    'cplitemvalue' # Valores muy dispares que se alejan de la solucion de los paciente\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41d8addf-0794-4f16-b84e-6b51b042908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ventilation                                  3715\n",
    "#DVT Prophylaxis                              3296\n",
    "#Airway                                       3141\n",
    "#Care Limitation                              2967\n",
    "#Stress Ulcer Prophylaxis                     2946\n",
    "\n",
    "def has_Ventilation (row):\n",
    "    return 1 if row['cplgroup'] == 'Ventilation' else 0\n",
    "\n",
    "def has_DVT_Prophylaxis (row):\n",
    "    return 1 if row['cplgroup'] == 'DVT Prophylaxis' else 0\n",
    "\n",
    "def has_Airway (row):\n",
    "    return 1 if row['cplgroup'] == 'Airway' else 0\n",
    "\n",
    "def has_Care_Limitation (row):\n",
    "    return 1 if row['cplgroup'] == 'Care Limitation' else 0\n",
    "\n",
    "def has_Stress_Ulcer_Prophylaxis  (row):\n",
    "    return 1 if row['cplgroup'] == 'Stress Ulcer Prophylaxis' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd03b257-a5d1-4220-b565-45f7c3507212",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dfs = dfs[\"carePlanGeneral\"]['patientunitstayid']\n",
    "\n",
    "category_Ventilation               = dfs[\"carePlanGeneral\"].apply(lambda row : has_Ventilation(row), axis=1)\n",
    "category_DVT_Prophylaxis           = dfs[\"carePlanGeneral\"].apply(lambda row : has_DVT_Prophylaxis(row), axis=1)\n",
    "category_Airway                    = dfs[\"carePlanGeneral\"].apply(lambda row : has_Airway(row), axis=1)\n",
    "category_Care_Limitation           = dfs[\"carePlanGeneral\"].apply(lambda row : has_Care_Limitation(row), axis=1)\n",
    "category_Stress_Ulcer_Prophylaxis  = dfs[\"carePlanGeneral\"].apply(lambda row : has_Stress_Ulcer_Prophylaxis(row), axis=1)\n",
    "\n",
    "_category_Ventilation                = pd.DataFrame(category_Ventilation, columns=['Categoria_Ventilacion'])\n",
    "_category_DVT_Prophylaxis            = pd.DataFrame(category_DVT_Prophylaxis, columns=['Categoria_DVT_Prophylaxis'])\n",
    "_category_Airway                     = pd.DataFrame(category_Airway, columns=['Categoria_Airway'])\n",
    "_category_Care_Limitation            = pd.DataFrame(category_Care_Limitation, columns=['Categoria_Care_Limitation'])\n",
    "_category_Stress_Ulcer_Prophylaxis   = pd.DataFrame(category_Stress_Ulcer_Prophylaxis, columns=['Categoria_Stress_Ulcer_Prophylaxis'])\n",
    "\n",
    "categoria = pd.concat([_dfs, _category_Ventilation ,_category_DVT_Prophylaxis,_category_Airway, _category_Care_Limitation, _category_Stress_Ulcer_Prophylaxis ], axis=1)\n",
    "#categoria = categoria.drop_duplicates()\n",
    "categoria = categoria.groupby(['patientunitstayid']).sum()\n",
    "categoria = categoria.reset_index()\n",
    "\n",
    "dfs['carePlanGeneral'] = categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983db2b-2824-4c6e-8c6b-aaf77354e4f7",
   "metadata": {},
   "source": [
    "<center><h2><b>careplangoal</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b97650a3-375e-4943-b11f-dd81427aa8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar NaN por un valor por defecto\n",
    "dfs['carePlanGoal']['cplitemvalue'] = dfs['carePlanGoal']['cplgoalvalue'].fillna('_Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e806bf-aa61-4920-b685-2c4601ea3843",
   "metadata": {},
   "source": [
    "<center><h2><b>careplaninfectiousdisease</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0234e0a-889f-4c2e-8aa7-bde7f80894a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['carePlanInfectiousDisease'] = dfs['carePlanInfectiousDisease'].drop(columns=[\n",
    "    'responsetotherapy', # Solo tiene 2 no nulls\n",
    "    'treatment' # La mitad son nulls y no es muy útil para empezar\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde23cb2-150a-4fb5-94ff-855cfb83ae6f",
   "metadata": {},
   "source": [
    "<center><h2><b>customlab</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53d44ea2-3470-4467-93c0-4a495ae6c41c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs['customLab'] = dfs['customLab'].drop(columns=[\n",
    "    'labotherresult', # Igual a labothervaluetext\n",
    "])\n",
    "\n",
    "# Normalizar a minúsculas\n",
    "dfs['customLab']['labothervaluetext'] = dfs['customLab']['labothervaluetext'].apply(lambda val: val.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a2786e-e673-463d-8694-6d1ed827f269",
   "metadata": {},
   "source": [
    "<center><h2><b>diagnosis</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb3df86b-19cb-4d82-8c1c-f42de8e9c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar NaN por un valor por defecto\n",
    "dfs['diagnosis']['icd9code'] = dfs['diagnosis']['icd9code'].fillna('_Unknown')\n",
    "\n",
    "# Redondear offset al múltiplo de 50 más cercano hacia abajo para eliminar duplicados\n",
    "# TODO: Hacer en todas las tablas\n",
    "#dfs['diagnosis']['diagnosisoffset'] = dfs['diagnosis'].apply(lambda row: (int(row['diagnosisoffset'])//50) * 50, axis=1)\n",
    "#dfs['diagnosis'] = dfs['diagnosis'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6a0eaac-c092-433d-8be9-6054f2388647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANTENER 3 DIAGNOSIS MÁS IMPORTANTES POR SECUENCIA Y PRIORIDAD\n",
    "new_df = pd.DataFrame(columns=['patientunitstayid', 'diag1', 'diag2', 'diag3', 'additional1', 'additional2', 'additional3'])\n",
    "\n",
    "def clean_diagnosisstring(group):\n",
    "    pusID, group_df = group\n",
    "    priority = {\n",
    "        'Primary': [],\n",
    "        'Major':  [],\n",
    "        'Other': []\n",
    "    }\n",
    "    \n",
    "    # Obtener las diagnossis de un paciente\n",
    "    for i, row in group_df.iterrows():\n",
    "        if row['diagnosisstring'] == row['diagnosisstring'] and row['diagnosispriority'] == row['diagnosispriority']: # not NaN\n",
    "            diag = row['diagnosisstring'].split('|')[-1]\n",
    "            priority_lv = row['diagnosispriority']\n",
    "            \n",
    "            priority[priority_lv].append(diag)\n",
    "    \n",
    "    return [pusID] + (priority['Primary'] + priority['Major'] + priority['Other'] + ['None', 'None', 'None'])[:3]\n",
    "\n",
    "new_df = pd.DataFrame(columns=['patientunitstayid', 'last1', 'last2', 'last3'])\n",
    "for i,  group in enumerate(dfs['diagnosis'].groupby('patientunitstayid')):\n",
    "    row = clean_diagnosisstring(group)\n",
    "    new_df.loc[i] = row\n",
    "\n",
    "dfs['diagnosis'] = new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ee099-863b-4113-87b4-f3e8c42279b9",
   "metadata": {},
   "source": [
    "<center><h2><b>hospital</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90cac4ab-991e-49c7-98b1-3e84d64b8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar NaN por un valor por defecto\n",
    "dfs['hospital']['numbedscategory'] = dfs['hospital']['numbedscategory'].fillna('_Unknown')\n",
    "dfs['hospital']['region'] = dfs['hospital']['region'].fillna('_Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c0f8fa-4268-4f3c-8a0f-870dc9ad8281",
   "metadata": {},
   "source": [
    "<center><h2><b>Infusiondrug</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adb3dfd1-effc-498c-bd1f-ded1a1a04cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar NaN numéricos por un valor por defecto\n",
    "dfs['infusiondrug']['drugrate'] = dfs['infusiondrug']['drugrate'].fillna(-1)\n",
    "dfs['infusiondrug']['infusionrate'] = dfs['infusiondrug']['infusionrate'].fillna(-1)\n",
    "dfs['infusiondrug']['drugamount'] = dfs['infusiondrug']['drugamount'].fillna(-1)\n",
    "dfs['infusiondrug']['volumeoffluid'] = dfs['infusiondrug']['volumeoffluid'].fillna(-1)\n",
    "dfs['infusiondrug']['patientweight'] = dfs['infusiondrug']['patientweight'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "567cdf2c-4ac9-4170-a432-16e642a314ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Mantener las medidas más reciente para cada medicamento de los 10 que sean más frecuentes\n",
    "#\n",
    "\n",
    "# Medicamentos a tener en cuenta\n",
    "acceptedDrugs = set(['fentanyl', 'propofol', 'norepinephrine', 'insulin', 'heparin', 'midazolam', 'dexmedetomidine', 'amiodarone', 'heparin', 'pantoprazole'])\n",
    "\n",
    "def parse_drug_name(drug):\n",
    "    drug = drug.lower()\n",
    "    m = re.search('(.+)\\(.+?$', drug)\n",
    "\n",
    "    if type(m) == re.Match:\n",
    "        return m.group(1).strip()\n",
    "    else:\n",
    "        return drug\n",
    "\n",
    "patients = {}\n",
    "columns = []\n",
    "for drug in acceptedDrugs:\n",
    "    columns += ['last_' + drug, 'last_' + drug + '_drugrate', 'last_' + drug + '_infusionrate',\n",
    "                'last_' + drug + '_drugamount', 'last_' + drug + '_volumeoffluid', 'last_' + drug + '_patientweight']\n",
    "\n",
    "for i, row in dfs['infusiondrug'].iterrows():\n",
    "    pusID          = row['patientunitstayid']\n",
    "    drug           = parse_drug_name(row['drugname'])\n",
    "    drugrate       = row['drugrate']\n",
    "    infusionrate   = row['infusionrate']\n",
    "    drugamount     = row['drugamount']\n",
    "    volumeoffluid  = row['volumeoffluid']\n",
    "    patientweight  = row['patientweight']\n",
    "    infusionOffset = row['infusionoffset'] \n",
    "    \n",
    "    if infusionOffset < 0 or drug not in acceptedDrugs:\n",
    "        continue\n",
    "    else:\n",
    "        if pusID not in patients:\n",
    "            patients[pusID] = {}\n",
    "            \n",
    "            for targetdrug in acceptedDrugs:\n",
    "                patients[pusID][targetdrug] = { 'drugrate': -1, 'infusionrate': -1, 'drugamount': -1, 'volumeoffluid': -1, 'patientweight': -1, 'lastOffset': float('inf') }\n",
    "        else:\n",
    "            if infusionOffset > patients[pusID][drug]['lastOffset']:\n",
    "                patients[pusID][drug] = { 'drugrate': drugrate, 'infusionrate': infusionrate, 'drugamount': drugamount, 'volumeoffluid': volumeoffluid, 'patientweight': patientweight, 'lastOffset': infusionOffset }\n",
    "\n",
    "new_df = pd.DataFrame(columns=columns)\n",
    "keys = list(patients.keys())\n",
    "\n",
    "new_df['patientunitstayid'] = keys\n",
    "\n",
    "for drug in acceptedDrugs:\n",
    "    new_df['last_' + drug] = [ -1 if patients[key][drug]['lastOffset'] == float('inf') else patients[key][drug]['lastOffset'] for key in keys ]\n",
    "    new_df['last_' + drug + '_drugrate'] = [ patients[key][drug]['drugrate'] for key in keys ]\n",
    "    new_df['last_' + drug + '_infusionrate'] = [ patients[key][drug]['infusionrate'] for key in keys ]\n",
    "    new_df['last_' + drug + '_drugamount'] = [ patients[key][drug]['drugamount'] for key in keys ]\n",
    "    new_df['last_' + drug + '_volumeoffluid'] = [ patients[key][drug]['volumeoffluid'] for key in keys ]\n",
    "    new_df['last_' + drug + '_patientweight'] = [ patients[key][drug]['patientweight'] for key in keys ]\n",
    "\n",
    "dfs['infusiondrug'] = new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722b01a-33bf-4dd3-9a57-8fac9484f1b5",
   "metadata": {},
   "source": [
    "<center><h2><b>intakeoutput</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a743872f-2535-4cf9-8e9d-fc77412b9b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs['intakeOutput'] = dfs['intakeOutput'].drop(columns=[\n",
    "    'intaketotal', # Computada en otra variable\n",
    "    'outputtotal', # Computada en otra variable\n",
    "    'cellpath', # Redundante en celltext\n",
    "    'cellvaluetext' # dependiente de cellvaluenumeric\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d738c9-12a9-49f0-b78f-f9cca26995b2",
   "metadata": {},
   "source": [
    "<center><h2><b>lab</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7df71d78-c264-4002-89f4-5de96702d671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quitar filas sin laboresult\n",
    "df = dfs['lab']\n",
    "dfs['lab'] = df[df['labresult'].notnull()]\n",
    "\n",
    "dfs['lab'] = dfs['lab'].drop(columns=[\n",
    "    'labtypeid', # Irrelevante\n",
    "    'labname', # Irrelevante\n",
    "    'labresulttext', # Redundante con labResult\n",
    "    'labresultrevisedoffset' # Reundante con labresultoffset\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b6489-7901-45f7-a99b-dcdb5fb95a45",
   "metadata": {},
   "source": [
    "<center><h2><b>medication</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df898c3a-19ef-44d0-94ae-c9c3b428bb77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = dfs['medication']\n",
    "\n",
    "# name_code = {}\n",
    "# code_name = {}\n",
    "# for i, row in df.iterrows():\n",
    "#     if row['drugname'] == row['drugname'] and row['drughiclseqno'] == row['drughiclseqno']:\n",
    "#         name_code[row['drugname']] = row['drughiclseqno']\n",
    "#         code_name[row['drughiclseqno']] = row['drugname']\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     drugname = row['drugname']\n",
    "#     code = row['drughiclseqno']\n",
    "    \n",
    "#     if drugname != drugname: # NaN\n",
    "#         if code in code_name:\n",
    "#             row['drugname'] = code_name[code]\n",
    "#     if code != code: # NaN\n",
    "#         if drugname in name_code:\n",
    "#             row['drughiclseqno'] = name_code[drugname]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a11ea221-56a4-4854-8830-90e138e97a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Parsear dosage con drugname\n",
    "# TODO: Arreglar drugname con drughiclseqno\n",
    "\n",
    "# Quitar filas sin laboresult\n",
    "df = dfs['medication']\n",
    "dfs['medication'] = df[df['drugname'].notnull()]\n",
    "\n",
    "dfs['medication'] = dfs['medication'].drop(columns=[\n",
    "    'drugorderoffset', # Irrelevante\n",
    "    'drugivadmixture', # No parece relevante\n",
    "    'drugordercancelled', # Irrelevante\n",
    "    'loadingdose', # Solamente hay 8 non-nulls\n",
    "    #'prn', # ? Redundante con frequency\n",
    "    #'gtc' # ? No parece que tenga relevancia\n",
    "], axis=1)\n",
    "\n",
    "#\n",
    "# TODO:\n",
    "# 4   drughiclseqno      42150 non-null  float64\n",
    "# 5   dosage             41607 non-null  object \n",
    "# 6   routeadmin         44926 non-null  object \n",
    "# 7   frequency          39889 non-null  object \n",
    "# 8   prn                44941 non-null  object \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e17b2-134e-4a0a-995c-4a4ab9c01c13",
   "metadata": {},
   "source": [
    "<center><h2><b>microLab</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76841056-f5ed-4e3e-a937-0c0df5302047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs['microLab'] = dfs['microLab'].drop(columns=[\n",
    "    'antibiotic', # TODO: ? Irrelevante\n",
    "    'sensitivitylevel', # No parece relevante\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d76f1-a410-4850-85b5-7c406b8e995a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>note</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c8493b4-293a-429a-9324-8d27bc3e3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar NaN por un valor por defecto\n",
    "dfs['note']['notetext'] = dfs['note']['notetext'].fillna('_Unknown')\n",
    "\n",
    "dfs['note'] = dfs['note'].drop(columns=[\n",
    "    'noteenteredoffset', # Irrelevante\n",
    "    'notetype', # No parece relevante\n",
    "    'notevalue', # Parece tener información sobre notetext\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e4116b-f2ba-45b5-a75d-438449bfda1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>nurseAssessment</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4afd00c9-c7c7-4f50-8345-4ce43827de83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: ? Parece que hay múltiples assessments de diferentes enfermeras al mismo tiempo con diagnósticos diferentes.\n",
    "# TODO: Unir celllabel\tcellattribute\tcellattributevalue\n",
    "# TODO: Hacer algo con cellattributepath\n",
    "\n",
    "# Reemplazar NaN por un valor por defecto\n",
    "dfs['nurseAssessment']['cellattributevalue'] = dfs['nurseAssessment']['cellattributevalue'].fillna('_Unknown')\n",
    "\n",
    "dfs['nurseAssessment'] = dfs['nurseAssessment'].drop(columns=[\n",
    "    'nurseassessentryoffset', # Irrelevante\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0b5ce-e2cd-4ee7-8e18-e3a02503e35d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>nurseCare</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "030bcd3b-213f-4984-8be8-b3925c290684",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['nurseCare'] = dfs['nurseCare'].drop(columns=[\n",
    "    'nursecareentryoffset', # Irrelevante\n",
    "    'celllabel' # cellattribute es más detallada\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6e75c-9403-440e-aeae-f44fcea2348f",
   "metadata": {},
   "source": [
    "<center><h2><b>nurseCharting</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ca72fa9-cfca-4aa0-be88-acf0ce360650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer algo con esta mierda\n",
    "\n",
    "dfs['nurseCharting'] = dfs['nurseCharting'].drop(columns=[\n",
    "    'nursingchartentryoffset' # Irrelevante\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d01d8b-46c9-4553-ab72-4841d5699d17",
   "metadata": {},
   "source": [
    "<center><h2><b>pastHistory</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10558dbd-b304-4598-aa91-85e815b35a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['pastHistory'] = dfs['pastHistory'].drop(columns=[\n",
    "    'pasthistoryenteredoffset', # Irrelevante\n",
    "    'pasthistoryvaluetext' # Igual que pasthistoryvalue\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a69e008-b82c-40e4-971b-86e59583a8b7",
   "metadata": {},
   "source": [
    "<center><h2><b>patient</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a1f29a4-ccca-49e5-9be2-55d4355db8a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_14976\\2954303803.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  previous_visits_df = df[\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Añadir a paciente la media del n de minutos que ha estado en la UCI\n",
    "#\n",
    "def parse_avg_unit_stay(row, df):\n",
    "    total_mins = 0\n",
    "    total_entries = 0\n",
    "    \n",
    "    previous_visits_df = df[\n",
    "        df['patienthealthsystemstayid'] == row['patienthealthsystemstayid']\n",
    "    ][\n",
    "        df['patientunitstayid'] < row['patientunitstayid']\n",
    "    ]\n",
    "    \n",
    "    # Obtener las diagnossis de un paciente\n",
    "    for i, row in previous_visits_df.iterrows():\n",
    "        mins = row['unitdischargeoffset']\n",
    "        total_mins += mins\n",
    "        total_entries += 1\n",
    "    \n",
    "    return 0 if total_mins == 0 else total_mins//total_entries # Integer division\n",
    "\n",
    "avg_unit_stay = []\n",
    "for i,  row in dfs['patient'].iterrows():\n",
    "    n = parse_avg_unit_stay(row, dfs['patient'])\n",
    "    avg_unit_stay.append(n)\n",
    "\n",
    "dfs['patient']['avg_unit_stay'] = avg_unit_stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f78ea8a6-3887-463f-89b0-3d4d4c93b6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_14976\\4073688880.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  previous_visits_df = df[\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Añadir a paciente la media del n de minutos que ha estado en el hospital\n",
    "#\n",
    "def parse_avg_hospital_stay(row, df):\n",
    "    total_mins = 0\n",
    "    total_entries = 0\n",
    "    \n",
    "    previous_visits_df = df[\n",
    "        df['patienthealthsystemstayid'] == row['patienthealthsystemstayid']\n",
    "    ][\n",
    "        df['patientunitstayid'] < row['patientunitstayid']\n",
    "    ]\n",
    "    \n",
    "    # Obtener las diagnossis de un paciente\n",
    "    for i, row in previous_visits_df.iterrows():\n",
    "        mins = row['hospitaldischargeoffset']\n",
    "        total_mins += mins\n",
    "        total_entries += 1\n",
    "    \n",
    "    return 0 if total_mins == 0 else total_mins//total_entries # Integer division\n",
    "\n",
    "avg_unit_stay = []\n",
    "for i,  row in dfs['patient'].iterrows():\n",
    "    n = parse_avg_hospital_stay(row, dfs['patient'])\n",
    "    avg_unit_stay.append(n)\n",
    "\n",
    "dfs['patient']['avg_hospital_stay'] = avg_unit_stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9944819e-a1e7-497d-8bd0-12c5f6c38511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Añadir BMI en admisión\n",
    "#\n",
    "def bmi(row):\n",
    "    height = row['admissionheight']\n",
    "    weight = row['admissionweight']\n",
    "    \n",
    "    if height != height or weight != weight: # has NaN\n",
    "        return -1\n",
    "    else:\n",
    "        return height/weight\n",
    "\n",
    "dfs['patient']['admission_bmi'] = dfs['patient'].apply(bmi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fa9cb86-dcfb-4037-869d-f66ac4bc463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def clean_age(row):\n",
    "    age = row['age']\n",
    "    \n",
    "    if age == '':\n",
    "        return 50 # TODO: Median\n",
    "    elif age == '> 89':\n",
    "        return 100\n",
    "    elif math.isnan(float(age)):\n",
    "        return 50 # \"\"\n",
    "    else:\n",
    "        return int(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ca67ce3-d6a8-44c0-9b73-a388834025c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sepsis, pulmonary              -> 121                                                                                                                                                                    121\n",
    "#Diabetic ketoacidosis          -> 105                                                                                                                                                                 105\n",
    "#CHF, congestive heart failure  -> 102   \n",
    "\n",
    "def randomApache():\n",
    "    num = random.randint(1, 3)\n",
    "    \n",
    "    if(num == 1): \n",
    "        return 'CHF, congestive heart failure'\n",
    "    \n",
    "    elif (num == 2): \n",
    "        return 'Diabetic ketoacidosis'\n",
    "    \n",
    "    else: return 'Sepsis, pulmonary'\n",
    "     \n",
    "def clean_apacheadmissiondx(row):\n",
    "    apache = row['apacheadmissiondx']\n",
    "    \n",
    "    if apache != apache:\n",
    "        return randomApache() # \"\"\n",
    "    else:\n",
    "        return apache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a3e313e-4f11-410d-bc51-615d6b68d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 177.80    151\n",
    "# 172.70    146\n",
    "# 167.60    133\n",
    "# 165.10    127\n",
    "                                                                                                                                                    \n",
    "def randomAdmissionheight():\n",
    "    num = random.randint(1, 4)\n",
    "    \n",
    "    if(num == 1): \n",
    "        return 177.80\n",
    "    \n",
    "    elif (num == 2): \n",
    "        return 172.70\n",
    "    \n",
    "    elif (num == 3): \n",
    "        return 167.60\n",
    "    \n",
    "    else: return 165.10\n",
    "     \n",
    "def clean_admissionheight(row):\n",
    "    admissionheight = row['admissionheight']\n",
    "    \n",
    "    if math.isnan(float(admissionheight)):\n",
    "        return randomAdmissionheight() # \"\"\n",
    "    else:\n",
    "        return admissionheight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57b1a3ae-32d5-4b19-9589-d78d10d235f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random\n",
    "def clean_gender(row):\n",
    "    gender = row['gender']\n",
    "    \n",
    "    if gender != gender:\n",
    "        if random.randint(1, 2) % 2 == 0: return 'Male'\n",
    "        else: return 'Famale'\n",
    "    else:\n",
    "        return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3789afb1-f9ab-4a2b-a040-e5a47c3a2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caucasian\n",
    "def clean_ethnicity(row):\n",
    "    ethnicity = row['ethnicity']\n",
    "    \n",
    "    if ethnicity != ethnicity:\n",
    "        return 'Caucasian'\n",
    "    else:\n",
    "        return ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfe14c46-1f45-4a44-92a6-8f717de668e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emergency Department\n",
    "def clean_hospitaladmitsource(row):\n",
    "    hospitalAdmit = row['hospitaladmitsource']\n",
    "    \n",
    "    if hospitalAdmit != hospitalAdmit:\n",
    "        return 'Emergency Department' # \"\"\n",
    "    else:\n",
    "        return hospitalAdmit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ea1aa73-68ca-4829-b9e9-7e690d05e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_admissionweight(row, df):\n",
    "    admissionweight = row['admissionweight']\n",
    "    \n",
    "    if math.isnan(float(admissionweight)):\n",
    "        return  df[df['age']==row['age']]['admissionweight'].median()\n",
    "    else:\n",
    "        return admissionweight    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6dd5988e-9c84-4c31-861b-224dacf4dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feature idea - BMI\n",
    "# TODO: ? Cual es más importante, unitDischargeOffset u hospitalDischargeOffset  \n",
    "\n",
    "# Drop\n",
    "dfs['patient'] = dfs['patient'].drop(columns=[\n",
    "    'wardid', # ? Tiene pinta de que no va a ser muy importante\n",
    "    'patienthealthsystemstayid', # Irrelevante\n",
    "    'hospitaldischargeyear', # Irrelevante. Solo hay datos de los años 2014 y 2015\n",
    "    'hospitaladmittime24', # Drop a priori. No parece importante\n",
    "    'hospitaldischargetime24', # Drop a priori. No parece importante\n",
    "    'hospitaldischargelocation', # No parece muy relevante\n",
    "    'unittype', # Parece que ya está presente en otras partes\n",
    "    'unitadmittime24', # No parece muy relevante\n",
    "    'unitadmitsource', # ?\n",
    "    'unitstaytype', # No parece muy relevante\n",
    "    'dischargeweight', # No parece que sea muy relevante el peso cuando esté muerto\n",
    "    'unitdischargetime24', # Irrelevante\n",
    "    'unitdischargelocation', # Irrelevante\n",
    "    'hospitaldischargestatus', # Irrelevante\n",
    "    'unitdischargestatus',\n",
    "    'uniquepid'\n",
    "], axis=1)\n",
    "\n",
    "# Eliminar NaN TODO\n",
    "#dfs['patient'] = dfs['patient'].dropna()\n",
    "\n",
    "# Age\n",
    "dfs['patient']['age']                 = dfs['patient'].apply(clean_age, axis=1)\n",
    "\n",
    "# Apacheadmissiondx\n",
    "dfs['patient']['apacheadmissiondx']   = dfs['patient'].apply(clean_apacheadmissiondx, axis=1)\n",
    "\n",
    "# Hospitaladmitsource\n",
    "dfs['patient']['hospitaladmitsource'] = dfs['patient'].apply(clean_hospitaladmitsource, axis=1)\n",
    "\n",
    "# Gender\n",
    "dfs['patient']['gender']              = dfs['patient'].apply(clean_gender, axis=1)\n",
    "\n",
    "# ethnicity\n",
    "dfs['patient']['ethnicity']           = dfs['patient'].apply(clean_ethnicity, axis=1)\n",
    "\n",
    "# admissionheight\n",
    "dfs['patient']['admissionheight']     = dfs['patient'].apply(clean_admissionheight, axis=1)\n",
    "\n",
    "# admissionweight -> OUTLAYERS TODO:\n",
    "dfs['patient']['admissionweight']     = dfs['patient'].apply(lambda row : clean_admissionweight(row, dfs['patient']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c203e-f148-4570-8b8e-87eef9e885cf",
   "metadata": {},
   "source": [
    "<center><h2><b>physicalExam</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e42fbf72-c582-4f80-b485-5b73f012169a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set(dfs['physicalExam']['physicalexamvalue'])\n",
    "dfs['physicalExam']['physicalexamtext'] = dfs['physicalExam']['physicalexamtext'].fillna('_Unknown')\n",
    "# BPDiastolic current\n",
    "# BPDiastolic highest\n",
    "# BPDiastolic lowest\n",
    "# BPSystolic current\n",
    "# BPSystolic highest\n",
    "# BPSystolic lowest\n",
    "\n",
    "# Blood loss\n",
    "# Dialysis net\n",
    "\n",
    "# O2 Sat current\n",
    "# O2 Sat lowest\n",
    "# O2 Sat highest\n",
    "# Urine\n",
    "# Intubated\n",
    "# Comatose\n",
    "# Ventilated\n",
    "\n",
    "def physical_exam_info(group):\n",
    "    pusID, group_df = group\n",
    "    d = {\n",
    "        'BP (diastolic) Current': -1,\n",
    "        'BP (diastolic) Highest': -1,\n",
    "        'BP (diastolic) Lowest' : -1,\n",
    "        \n",
    "        'BP (systolic) Current': -1,\n",
    "        'BP (systolic) Highest': -1,\n",
    "        'BP (systolic) Lowest' : -1,\n",
    "        \n",
    "        'Blood Loss': -1,\n",
    "        'Dialysis Net': -1,\n",
    "        'O2 Sat% Current': -1,\n",
    "        'O2 Sat% Highest': -1,\n",
    "        'O2 Sat% Lowest': -1,\n",
    "        'Urine': -1,\n",
    "        'Intubated': -1,\n",
    "        'Comatose': -1,\n",
    "        'Ventilated': -1,\n",
    "        \n",
    "        'Motor Score': -1,\n",
    "        'Verbal Score': -1,\n",
    "        'Eyes Score': -1\n",
    "    }\n",
    "    \n",
    "    last_offset = float('inf')\n",
    "    \n",
    "    # Obtener las diagnossis de un paciente\n",
    "    for i, row in group_df.iterrows():\n",
    "        off = row['physicalexamoffset']\n",
    "        \n",
    "        if off < last_offset:\n",
    "            last_offset = off\n",
    "            diag = row['physicalexamvalue']\n",
    "            val = row['physicalexamtext']\n",
    "            \n",
    "            \n",
    "            if diag in d:\n",
    "                d[diag] = val\n",
    "    \n",
    "    for i, row in group_df.iterrows():\n",
    "        path = row['physicalexampath']\n",
    "        part = path.split('/')[-2]\n",
    "            \n",
    "        if part in d:\n",
    "            d[part] = row['physicalexamtext']\n",
    "    \n",
    "    return [pusID, d['BP (diastolic) Current'], d['BP (diastolic) Highest'], d['BP (diastolic) Lowest'],\n",
    "            d['BP (systolic) Current'], d['BP (systolic) Highest'], d['BP (systolic) Lowest'], d['Blood Loss'],\n",
    "            d['Dialysis Net'], d['O2 Sat% Current'], d['O2 Sat% Highest'], d['O2 Sat% Lowest'], d['Urine'], d['Intubated'], d['Comatose'], d['Ventilated'],\n",
    "            d['Motor Score'], d['Verbal Score'], d['Eyes Score']]\n",
    "\n",
    "new_df = pd.DataFrame(columns=[\n",
    "    'patientunitstayid', 'BPD_Current', 'BPD_Highest', 'BPD_Lowest', 'BPS_Current', 'BPS_Highest', 'BPS_Lowest', 'Blood_Loss', 'Dialysis_Net',\n",
    "    'O2Sat_Current', 'O2Sat_Highest', 'O2Sat_Lowest', 'Urine', 'Intubated', 'Comatose', 'Ventilated', 'Motor', 'Verbal', 'Eyes'\n",
    "])\n",
    "\n",
    "for i,  group in enumerate(dfs['physicalExam'].groupby('patientunitstayid')):\n",
    "    row = physical_exam_info(group)\n",
    "    new_df.loc[i] = row\n",
    "\n",
    "dfs['physicalExam'] = new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4385e3-f224-4e1a-aaf5-a9ef3944a4fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>respiratoryCare</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f36d6194-4b52-4620-8985-8e0f2d9a2e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Me quedo con el numero máximo de cada paciente\n",
    "def clean_respiratoryCare(row, df):\n",
    "    respiratoryCare = row['currenthistoryseqnum']\n",
    "           \n",
    "    return  df[df['patientunitstayid']==row['patientunitstayid']]['currenthistoryseqnum'].max()\n",
    "\n",
    "# Clasifico\n",
    "def range_currenthistoryseqnum(row, df):\n",
    "    median = 3.00  # df['currenthistoryseqnum'].median()\n",
    "    currenthistoryseqnum = row ['currenthistoryseqnum']\n",
    "    \n",
    "    if (currenthistoryseqnum<median):\n",
    "        return 'Low'\n",
    "    elif currenthistoryseqnum == median:\n",
    "        return 'Mid'\n",
    "    else:\n",
    "        return 'High' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4d2016e-20e0-4e9b-958f-7b765424942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['respiratoryCare']['currenthistoryseqnum'] = dfs['respiratoryCare'].apply(lambda row : clean_respiratoryCare(row, dfs['respiratoryCare']), axis=1)\n",
    "dfs['respiratoryCare']['currenthistoryseqnum'] = dfs['respiratoryCare'].apply(lambda row : range_currenthistoryseqnum(row, dfs['respiratoryCare']), axis=1)\n",
    "\n",
    "dfs['respiratoryCare'] = dfs['respiratoryCare'].drop(columns=[\n",
    "    'airwaysize', 'airwayposition', 'cuffpressure', 'apneaparams', 'lowexhmvlimit', 'hiexhmvlimit', 'lowexhtvlimit', 'hipeakpreslimit', 'lowpeakpreslimit',\n",
    "    'hirespratelimit', 'lowrespratelimit', 'sighpreslimit', 'lowironoxlimit', 'highironoxlimit', 'meanairwaypreslimit', 'peeplimit', 'cpaplimit',\n",
    "    'setapneainterval', 'setapneatv', 'setapneaippeephigh', 'setapnearr', 'setapneapeakflow', 'setapneainsptime', 'setapneaie', 'setapneafio2', \n",
    "    'respcarestatusoffset', 'airwaytype', 'ventstartoffset', 'ventstartoffset', 'ventstartoffset', 'priorventendoffset', 'ventendoffset', 'priorventstartoffset'\n",
    "], axis=1)\n",
    "\n",
    "#\n",
    "# TODO: airwaytype tiene nulls\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b6230-117a-47ef-9dc1-1a62a97bfe02",
   "metadata": {},
   "source": [
    "<center><h2><b>respiratoryCharting</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b82ff519-59e5-4aab-80ee-a8e683d2a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ?\n",
    "\n",
    "dfs['respiratoryCharting'] = dfs['respiratoryCharting'].drop(columns=[\n",
    "    'respchartentryoffset' # Irrelevante\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c22f4-4bb5-41d4-80ce-c158e87ecfe2",
   "metadata": {},
   "source": [
    "<center><h2><b>treatment</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bbe665df-fc57-4544-b3df-7cde4915448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ?\n",
    "\n",
    "dfs['treatment'] = dfs['treatment'].drop(columns=[\n",
    "    'activeupondischarge', # Irrelevante    \n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf475b-3d2c-406d-8d4e-893dd50427db",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>vitalAperiodic</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af8f0c96-f2fa-46b1-a2a3-63d5022456a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "dfs['vitalAperiodic'] = dfs['vitalAperiodic'].drop(columns=[\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "#\n",
    "# TODO: Tiene valores nulls\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c33848-7cb4-499f-8309-1ecfd9cdc49d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>vitalPeriodic</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "966028d7-986c-47a4-b3f5-13adfe9f0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "dfs['vitalPeriodic'] = dfs['vitalPeriodic'].drop(columns=[\n",
    "], axis=1)\n",
    "\n",
    "#\n",
    "# TODO: Tiene valores nulls\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7b42d-594f-42ef-b7d2-b4659c329b6a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<center><h2><b>Eliminar duplicados</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67c45d85-33ad-436a-8e42-4edcd422b1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab : 3989\n",
      "medication : 48\n",
      "microLab : 122\n",
      "note : 27\n",
      "pastHistory : 4\n",
      "respiratoryCare : 5041\n",
      "treatment : 137\n",
      "_allergyDrug : 2\n",
      "_allergyNonDrug : 1\n"
     ]
    }
   ],
   "source": [
    "for df_name in dfs:\n",
    "    n = len(dfs[df_name].duplicated())\n",
    "    dfs[df_name] = dfs[df_name].drop_duplicates()\n",
    "    \n",
    "    diff = n - len(dfs[df_name].duplicated())\n",
    "    if diff > 0:\n",
    "        print(df_name, ':', diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9fcf3-ef85-4ac4-ac9b-7cf7151b56b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<center><h2><b>Exportar a CSV</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f67cecc-893f-46c6-b021-980a9e56da95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df_name in dfs:\n",
    "    dfs[df_name].to_csv('../db/csv_clean/' + df_name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae904d6-8666-4430-84ca-7d538ac90bcb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<center><h2><b>Exportar a SQL</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4dcc64ae-ba50-4be4-9347-f953c9d8ae23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sqlite_path = \"../db/sqlite/eicu_v2_0_1_clean.sqlite3\"\n",
    "#os.remove(sqlite_path)\n",
    "conn = db.connect(sqlite_path)\n",
    "\n",
    "for df_name in dfs:\n",
    "    dfs[df_name].to_sql(df_name, conn, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
