{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d5308a6f-a6d1-46b1-9e13-92eeb3febf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as db\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1707430-21a2-46c7-8200-85c0b1d0396e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>Leer DB</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "647c573a-5a64-44b1-b78f-4640e98cf1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# medication: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False-\n",
    "#\n",
    "def read_csvs():\n",
    "    datasets = [ 'admissiondrug', 'admissionDx', 'allergy', 'apacheApsVar', 'apachePatientResult', 'apachePredVar', 'carePlanCareProvider', 'carePlanEOL', 'carePlanGeneral',\n",
    "                 'carePlanGoal', 'carePlanInfectiousDisease', 'customLab', 'diagnosis', 'hospital', 'infusiondrug', 'intakeOutput', 'lab',\n",
    "                 'medication',\n",
    "                 'microLab', 'note',\n",
    "                 'nurseAssessment', 'nurseCare', 'nurseCharting', 'pastHistory', 'patient', 'physicalExam', 'respiratoryCare', 'respiratoryCharting', 'treatment', 'vitalAperiodic',\n",
    "                 'vitalPeriodic']\n",
    "\n",
    "    dfs = {}\n",
    "\n",
    "    for ds_name in datasets:\n",
    "        #dfs[ds_name.lower()] = (pd.read_csv('../db/csv/' + ds_name + '.csv'), )\n",
    "        dfs[ds_name.lower()] = pd.read_csv('../db/csv_clean/' + ds_name + '.csv')\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "def read_query(q):\n",
    "    conn = db.connect('../db/sqlite/eicu_v2_0_1.sqlite3')\n",
    "    df = pd.read_sql_query(q, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_relationships(dfs):\n",
    "    relationships = []\n",
    "    pk_fk = json.loads( open('keys.json').read() )\n",
    "    i = 0\n",
    "\n",
    "    for ds_name in pk_fk:\n",
    "        #if pk_fk[ds_name]['pk'] != False:\n",
    "        #    dfs[ds_name][0].set_index(pk_fk[ds_name]['pk'])\n",
    "        \n",
    "        if pk_fk[ds_name]['fk'] != False and ds_name not in ('hospital', 'medication'):\n",
    "            #print(ds_name, pk[ds_name]['fk'])\n",
    "            fk_atr, target_table, target_atr = pk_fk[ds_name]['fk']\n",
    "            \n",
    "            #print((target_table, target_atr, ds_name, fk_atr))\n",
    "            relationships.append((target_table, target_atr, ds_name, fk_atr))\n",
    "            \n",
    "    relationships.append(('hospital', 'hospitalid', 'patient', 'hospitalid'))\n",
    "\n",
    "    return relationships\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "dfs = read_csvs()\n",
    "relationships = make_relationships(dfs)\n",
    "\n",
    "#feature_matrix, feature_defs = ft.dfs(\n",
    "#    dataframes=dfs,\n",
    "#    relationships=relationships,\n",
    "#    target_dataframe_name='patient',\n",
    "#)\n",
    "\n",
    "#dfs['patient'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2302ffb-bafe-4daf-a6b1-0242111a4beb",
   "metadata": {},
   "source": [
    "<center><h2><b>Transformación de columnas</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7d1919db-da40-4437-afd1-1c6d49731730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dividir en X e Y\n",
    "X = dfs['patient'][:-100]\n",
    "Y = dfs['patient'][-100:]\n",
    "\n",
    "def unionColumnas(X, Y, columnName):\n",
    "    return list(set(X[columnName]).union(set(Y[columnName])))\n",
    "\n",
    "categGender = unionColumnas(X, Y, \"gender\")\n",
    "categEthnicity = unionColumnas(X, Y, \"ethnicity\")\n",
    "categHospitalAdmitSource = unionColumnas(X, Y, \"hospitaladmitsource\")\n",
    "\n",
    "transformersX = [\n",
    "    ('patientunitstayid', 'drop', [0]),\n",
    "    ('gender', OneHotEncoder(categories=[categGender]), [1]),\n",
    "    ('age', 'passthrough', [2]), # TODO: Probar categórica\n",
    "    ('ethnicity', OneHotEncoder(categories=[categEthnicity]), [3]),\n",
    "    ('hospitalid', 'passthrough', [4]), # TODO: ''\n",
    "    ('apacheadmissiondx', 'drop', [5]), # JK\n",
    "    ('admissionheight', 'passthrough', [6]),\n",
    "    ('hospitaladmitoffset', 'passthrough', [7]),\n",
    "    ('hospitaladmitsource', OneHotEncoder(categories=[categHospitalAdmitSource]), [8]),\n",
    "    ('hospitaldischargeoffset', 'passthrough', [9]),\n",
    "    ('unitvisitnumber', 'passthrough', [10]),    \n",
    "    ('admissionweight', 'passthrough', [11]),\n",
    "    ('unitdischargeoffset', 'drop', [12]), # obv\n",
    "]\n",
    "\n",
    "# Normbrar el orden de columnas de 0 a n-1\n",
    "transformersY = deepcopy(transformersX)[:12] #Eliminar unitdischargeoffset\n",
    "\n",
    "for i, t in enumerate(transformersY): # Renumerar los indices de las columnas\n",
    "    transformersY[i][2].pop()\n",
    "    transformersY[i][2].append(i)\n",
    "\n",
    "# Transformar columnas\n",
    "X_T = ColumnTransformer(transformers=transformersX).fit_transform(X)\n",
    "Y_T = ColumnTransformer(transformers=transformersY).fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e66bf-82f0-420c-abea-735c915373ac",
   "metadata": {},
   "source": [
    "<center><h2><b>Entrenamiento</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "794bde4a-cd19-4784-a450-6ae83426fbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "trained_rf = rfreg.fit(X_T, X['unitdischargeoffset'])\n",
    "\n",
    "y_pred_rf = trained_rf.predict(Y_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9209c1e-dcc1-48f3-a9c2-ee1fda740e38",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>Calcular Error</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "30482cf3-e10f-401d-9ba7-aa2be36febac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4711.1175\n",
      "AVG: 3841.591\n",
      "DIFF: 869.5265\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(X['unitdischargeoffset'][:100], y_pred_rf)\n",
    "avg = sum(X['unitdischargeoffset']) / len(X['unitdischargeoffset'])\n",
    "\n",
    "print('MAE:', round(mae, 4))\n",
    "print('AVG:', round(avg, 4))\n",
    "print('DIFF:', round(abs(mae-avg), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
