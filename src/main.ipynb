{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d5308a6f-a6d1-46b1-9e13-92eeb3febf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as db\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1707430-21a2-46c7-8200-85c0b1d0396e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>Leer DB</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "647c573a-5a64-44b1-b78f-4640e98cf1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# medication: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False-\n",
    "# TODO: Feature idea - \n",
    "#\n",
    "def read_csvs():\n",
    "    datasets = [ 'admissiondrug', 'admissionDx', 'allergy', 'apacheApsVar', 'apachePatientResult', 'apachePredVar', 'carePlanCareProvider', 'carePlanEOL', 'carePlanGeneral', 'carePlanGoal',\n",
    "                 'carePlanInfectiousDisease', 'customLab', 'diagnosis', 'hospital', 'infusiondrug', 'intakeOutput', 'lab', 'medication', 'microLab', 'note', 'nurseAssessment', 'nurseCare',\n",
    "                 'nurseCharting', 'pastHistory', 'patient', 'physicalExam', 'respiratoryCare', 'respiratoryCharting', 'treatment', 'vitalAperiodic', 'vitalPeriodic']\n",
    "\n",
    "    dfs = {}\n",
    "\n",
    "    for ds_name in datasets:\n",
    "        #dfs[ds_name.lower()] = (pd.read_csv('../db/csv/' + ds_name + '.csv'), )\n",
    "        dfs[ds_name.lower()] = pd.read_csv('../db/csv_clean/' + ds_name + '.csv')\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "def sql_query(q):\n",
    "    conn = db.connect('../db/sqlite/eicu_v2_0_1_clean.sqlite3')\n",
    "    df = pd.read_sql_query(q, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_relationships(dfs):\n",
    "    relationships = []\n",
    "    pk_fk = json.loads( open('keys.json').read() )\n",
    "    i = 0\n",
    "\n",
    "    for ds_name in pk_fk:\n",
    "        #if pk_fk[ds_name]['pk'] != False:\n",
    "        #    dfs[ds_name][0].set_index(pk_fk[ds_name]['pk'])\n",
    "        \n",
    "        if pk_fk[ds_name]['fk'] != False and ds_name not in ('hospital', 'medication'):\n",
    "            #print(ds_name, pk[ds_name]['fk'])\n",
    "            fk_atr, target_table, target_atr = pk_fk[ds_name]['fk']\n",
    "            \n",
    "            #print((target_table, target_atr, ds_name, fk_atr))\n",
    "            relationships.append((target_table, target_atr, ds_name, fk_atr))\n",
    "            \n",
    "    relationships.append(('hospital', 'hospitalid', 'patient', 'hospitalid'))\n",
    "\n",
    "    return relationships\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "dfs = read_csvs()\n",
    "relationships = make_relationships(dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2302ffb-bafe-4daf-a6b1-0242111a4beb",
   "metadata": {},
   "source": [
    "<center><h2><b>Transformación de columnas</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d1919db-da40-4437-afd1-1c6d49731730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = dfs['patient']\n",
    "X = sql_query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM patient P INNER JOIN apacheApsVar A ON P.patientunitstayid = A.patientunitstayid\n",
    "\"\"\")\n",
    "\n",
    "y = X['unitdischargeoffset']\n",
    "\n",
    "X_T = ColumnTransformer(transformers=[\n",
    "    ('patientunitstayid',       'drop',           [0]),\n",
    "    ('gender',                  OneHotEncoder(),  [1]),\n",
    "    ('age',                     'passthrough',    [2]), # TODO: Probar categórica\n",
    "    ('ethnicity',               OneHotEncoder(),  [3]),\n",
    "    ('hospitalid',              'passthrough',    [4]), # TODO: ''\n",
    "    ('apacheadmissiondx',       'drop',           [5]), # JK\n",
    "    ('admissionheight',         'passthrough',    [6]),\n",
    "    ('hospitaladmitoffset',     'passthrough',    [7]),\n",
    "    ('hospitaladmitsource',      OneHotEncoder(), [8]),\n",
    "    ('hospitaldischargeoffset', 'passthrough',    [9]),\n",
    "    ('unitvisitnumber',         'passthrough',    [10]),    \n",
    "    ('admissionweight',         'passthrough',    [11]),\n",
    "    ('unitdischargeoffset',     'drop',           [12]), # obv\n",
    "    #('unabridgedunitlos', 'passthrough', [13])\n",
    "]).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9209c1e-dcc1-48f3-a9c2-ee1fda740e38",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h2><b>Entrenamiento y calcular Error</b></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "69f5f4ca-a4b5-43eb-bb68-6491938a6fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regresor</th>\n",
       "      <th>Average MAE</th>\n",
       "      <th>Standard Deviation MAE</th>\n",
       "      <th>Average R2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2059.738024</td>\n",
       "      <td>276.458815</td>\n",
       "      <td>0.385292</td>\n",
       "      <td>6.656238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Regresor  Average MAE  Standard Deviation MAE  Average R2      time\n",
       "0  Random Forest  2059.738024              276.458815    0.385292  6.656238"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import statistics as stat\n",
    "\n",
    "def cv_avg_std(reg, X, y, scoring):\n",
    "    maes = cross_val_score(reg, X, y, cv=5, scoring=scoring)\n",
    "    avg = stat.mean(maes)\n",
    "    std_dev = stat.variance(maes)**(1/2)\n",
    "    \n",
    "    return maes, avg, std_dev\n",
    "\n",
    "def make_df(datos_reg):\n",
    "    error_df = pd.DataFrame()\n",
    "\n",
    "    error_df['Regresor']                = datos_reg.keys()\n",
    "    error_df['Average MAE']             = [ abs(dato['avg']) for dato in datos_reg.values() ]\n",
    "    error_df['Standard Deviation MAE']  = [ dato['std_dev'] for dato in datos_reg.values() ]\n",
    "    error_df['Average R2']              = [ dato['avg_r2'] for dato in datos_reg.values() ]\n",
    "    error_df['time']                    = [ dato['time'] for dato in datos_reg.values() ]\n",
    "    \n",
    "    return error_df\n",
    "\n",
    "datos_reg = {}\n",
    "regressors = [\n",
    "    ('Random Forest', RandomForestRegressor())\n",
    "]\n",
    "\n",
    "# Medir tiempo y hacer predicciones para cada regresor\n",
    "for reg_name, reg in regressors:\n",
    "    start_time = time.time()\n",
    "\n",
    "    maes, avg, std_dev = cv_avg_std(reg, X_T, y, 'neg_mean_absolute_error')\n",
    "    maes, r2, _ = cv_avg_std(reg, X_T, y, 'r2')\n",
    "    \n",
    "    datos_reg[reg_name] = { 'avg': avg, 'std_dev': std_dev, 'time': time.time() - start_time }\n",
    "    datos_reg[reg_name]['avg_r2'] = r2\n",
    "\n",
    "make_df(datos_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596bff87-44aa-42d3-896c-0087346f84de",
   "metadata": {},
   "source": [
    "<center><h2>JOIN test</h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e447d2-a77b-4026-ad69-794667f915fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    SELECT *\n",
    "    FROM patient P INNER JOIN apachepatientresult A ON (P.patientunitstayid = A.patientunitstayid)\n",
    "\"\"\"\n",
    "\n",
    "conn = db.connect('test.db')\n",
    "df = pd.read_sql_query(q, conn)\n",
    "conn.close()\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
